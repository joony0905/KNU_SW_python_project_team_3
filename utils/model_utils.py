import numpy as np
from scipy.sparse import hstack, csr_matrix
import joblib
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import os

def plot_calibration_curve(model, X_test, y_test, model_name="model", n_bins=20):
        """
        ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì— ëŒ€í•œ calibration curveì™€ Brier scoreë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        """
        import matplotlib.pyplot as plt
        from sklearn.calibration import calibration_curve
        from sklearn.metrics import brier_score_loss
        
        # ì˜ˆì¸¡ í™•ë¥  ê°€ì ¸ì˜¤ê¸°
        if hasattr(model, "predict_proba"):
            y_prob = model.predict_proba(X_test)[:, 1]  # spam í™•ë¥ 
        else:
            raise ValueError("ëª¨ë¸ì— predict_proba ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        # Calibration curve ê³„ì‚°
        prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=n_bins)

        # Brier score ê³„ì‚° (ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë ˆì´ë¸” ê°„ì˜ í‰ê·  ì œê³± ì˜¤ì°¨)
        brier = brier_score_loss(y_test, y_prob)

        # ì‹œê°í™”
        plt.figure(figsize=(6, 6))
        plt.plot(prob_pred, prob_true, marker='o', label=f'{model_name} (Brier={brier:.4f})')
        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')
        plt.title('Calibration Curve')
        plt.xlabel('Predicted Probability')
        plt.ylabel('True Fraction of Positives')
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.show()

def load_model_and_vectorizer_Naive(vectorizer_path='model/nv_tf_idf_vectorizer.pkl', model_path='model/nv_spam_classifier.pkl'):
    try:
        vectorizer = joblib.load(vectorizer_path)
        model = joblib.load(model_path)
        return vectorizer, model
    except FileNotFoundError:
        raise FileNotFoundError("ëª¨ë¸ ë˜ëŠ” ë²¡í„°ë¼ì´ì € íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def load_model_and_vectorizer_Random(vectorizer_path='model/rf_count_vectorizer.pkl', model_path='model/rf_spam_classifier.pkl', category_columns_path='model/rf_category_columns.pkl'):
    try:
        vectorizer = joblib.load(vectorizer_path)
        model = joblib.load(model_path)
        category_columns = joblib.load(category_columns_path)
        return vectorizer, model, category_columns
    except FileNotFoundError:
        raise FileNotFoundError("ëª¨ë¸ ë˜ëŠ” ë²¡í„°ë¼ì´ì € íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def load_kmeans_and_if_models(
    if_count_vec_path = 'model/if_count_vectorizer.pkl',
    kmeans_path='model/kmeans_spam.pkl',
    if_model_dir='model/category_if_models/'
):
    """
    return if_count_vec, kmeans_model, if_models, score_ranges
    IF ì „ìš© countë²¡í„°/ KMeans ëª¨ë¸/ ì¹´í…Œê³ ë¦¬ë³„ Isolation Forest ëª¨ë¸/ range score ë¡œë“œ.
    í•´ë‹¹ íŒŒì¼ì´ ì—†ìœ¼ë©´ FileNotFoundError ë°œìƒ.
    IF ëª¨ë¸ë“¤ì€ í´ë” ë‚´ *.pkl íŒŒì¼ ì „ë¶€ ë¡œë“œ.
    """

    #if_countvec ë¡œë“œ
    if not os.path.exists(if_count_vec_path):
        raise FileNotFoundError(f"if_count ë²¡í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {if_count_vec_path}")
    if_count_vec = joblib.load(if_count_vec_path)

    # KMeans ë¡œë“œ
    if not os.path.exists(kmeans_path):
        raise FileNotFoundError(f"KMeans ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {kmeans_path}")
    kmeans_model = joblib.load(kmeans_path)

    # IF ëª¨ë¸ë“¤ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
    if not os.path.exists(if_model_dir):
        raise FileNotFoundError(f"IF ëª¨ë¸ ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {if_model_dir}")

    if_models = {}
    for filename in os.listdir(if_model_dir):
        if filename.startswith("if_category_") and filename.endswith(".pkl"):
            try:
                # ì˜ˆ: if_category_0.pkl
                category_id = int(filename.split('_')[-1].split('.')[0])
                model = joblib.load(os.path.join(if_model_dir, filename))
                if_models[category_id] = model
            except Exception as e:
                print(f"{filename} ë¡œë“œ ì‹¤íŒ¨: {e}")

    if not if_models:
        print(f"IF ëª¨ë¸ ë””ë ‰í„°ë¦¬ì— pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {if_model_dir}")

    #range score ë¡œë“œ
    ranges_path = os.path.join(if_model_dir, "if_score_ranges.pkl")
    
    if os.path.exists(ranges_path):
        score_ranges = joblib.load(ranges_path)
        print(f"âœ… score_ranges ë¡œë“œ ì™„ë£Œ: {ranges_path}")
    else:
        print(f"âš ï¸ score_ranges íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ranges_path}")
        score_ranges = {}
    
    return if_count_vec, kmeans_model, if_models, score_ranges

def rf_calculate_prob(message, vectorizer, model, category_columns):
    """
    CountVectorizer + log(1 + tf) + ë‹¨ì–´ ìˆ˜ feature + softmax í›„ì²˜ë¦¬ë¥¼ ì ìš©í•œ ì˜ˆì¸¡ í•¨ìˆ˜.

    Parameters:
        message (str): ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
        vectorizer: CountVectorizer ê°ì²´ (ì‚¬ì „ í•™ìŠµë¨)
        model: í•™ìŠµëœ RandomForestClassifier
        category_columns (list): ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (One-hot ìˆœì„œ)

    Returns:
        final_prob (float): Softmax ê°€ì¤‘ í‰ê·  ìŠ¤íŒ¸ í™•ë¥ 
    """

    # 1. ë©”ì‹œì§€ â†’ ë²¡í„°í™” (Count ê¸°ë°˜)
    message_vec = vectorizer.transform([message])

    # 2. log(1 + tf) ë³€í™˜
    message_log = message_vec.copy()
    message_log.data = np.log1p(message_log.data)

    # 3. ë¬¸ì¥ ê¸¸ì´ feature (ë‹¨ì–´ ìˆ˜)
    num_words = len(message.split())
    length_feature = csr_matrix([[num_words]])

    # 4. ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥  ì €ì¥
    probs = []

    for cat in category_columns:
        # One-hot ë²¡í„° ìƒì„±
        cat_sparse = build_category_vector(cat, category_columns)

        # ì „ì²´ ì…ë ¥ êµ¬ì„±: [log_count + length + category]
        combined = hstack([message_log, length_feature, cat_sparse])

        # ì˜ˆì¸¡
        prob = model.predict_proba(combined)[0][1]
        probs.append(prob)

    weights = rf_softmax(probs)
    final_prob = np.sum(np.array(probs) * weights)

    return final_prob

def nb_softmax(x):
    """
    nb Softmax í™•ë¥  ê³„ì‚° í•¨ìˆ˜.

    Parameters:
        x (array-like): ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ì ìˆ˜ (logits ë˜ëŠ” log í™•ë¥ )

    Returns:
        probs (np.ndarray): softmaxë¥¼ ì ìš©í•œ í´ë˜ìŠ¤ë³„ í™•ë¥  ë¶„í¬
        -> ì ìˆ˜ë“¤ì˜ í‰ê· 
    """
    exp_scores = np.exp(x - np.max(x))  # overflow ë°©ì§€
    probs = exp_scores / exp_scores.sum()
    return probs

def rf_softmax(x):
    """
    Softmax ê³„ì‚° í•¨ìˆ˜ (ëœë¤í¬ë ˆìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ í›„ì²˜ë¦¬ìš©).

    Parameters:
        x (array-like): ì‹¤ìˆ˜ ê°’ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì¸¡ í™•ë¥  ë“±)

    Returns:
        np.ndarray: softmaxë¥¼ ì ìš©í•œ ê²°ê³¼ê°’ (í™•ë¥  ë¶„í¬)
        -> ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥ ë¡œ ê°€ì¤‘ í‰ê· 
    """
    e_x = np.exp(x - np.max(x))  # Overflow ë°©ì§€ë¥¼ ìœ„í•´ ì•ˆì •ì„± ì²˜ë¦¬
    return e_x / e_x.sum()

def build_category_vector(category, category_columns):
    """
    ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ One-hot ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Parameters:
        category (str): í˜„ì¬ ë©”ì‹œì§€ì˜ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: 'bank', 'chat', 'ad' ë“±)
        category_columns (list): í•™ìŠµì— ì‚¬ìš©ëœ ì „ì²´ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        csr_matrix: í•´ë‹¹ categoryì— ëŒ€í•œ One-hot ì¸ì½”ë”© ê²°ê³¼ (í¬ì†Œ í–‰ë ¬ í˜•ì‹)

    ì„¤ëª…:
        - í•™ìŠµì— ì‚¬ìš©ëœ category_columns ê¸°ì¤€ìœ¼ë¡œ One-hot vectorë¥¼ ë§Œë“­ë‹ˆë‹¤.
        - categoryê°€ category_columnsì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•´ë‹¹ ìœ„ì¹˜ë§Œ 1, ë‚˜ë¨¸ì§€ëŠ” 0ì…ë‹ˆë‹¤.
        - categoryê°€ 'ad'ì²˜ëŸ¼ ì œì™¸ëœ í•­ëª©ì´ë©´ ì•„ë¬´ ìœ„ì¹˜ë„ 1ì´ ë˜ì§€ ì•Šì•„ ì „ì²´ê°€ 0ì¸ ë²¡í„°ê°€ ìƒì„±ë©ë‹ˆë‹¤.
        - ì´ êµ¬ì¡° ë•ë¶„ì— 'ad' ì¹´í…Œê³ ë¦¬ëŠ” í…ìŠ¤íŠ¸+ê¸¸ì´ ë²¡í„°ë§Œìœ¼ë¡œ ì¶”ë¡ í•˜ê²Œ ë©ë‹ˆë‹¤.
        - ad ì¹´í…Œê³ ë¦¬ëŠ” ë¬¸ì ì¢…ë¥˜ ë¶„ë¥˜ ì—†ì´ ê´‘ê³  ë¬¸ìë“¤ ì´ë§ë¼
    """
    onehot = pd.DataFrame([[0] * len(category_columns)], columns=category_columns)
    
    if category in category_columns:
        onehot[category] = 1  # adëŠ” category_columnsì— ì—†ìŒ â†’ ìë™ ì œì™¸

    return csr_matrix(onehot.values)

def get_naive_bayes_log_probs(processed_message, vectorizer, model, top_n=8):
    """
    Naive Bayes ëª¨ë¸ì„ ì‚¬ìš©í•´ ë¡œê·¸ìš°ë„ ê¸°ë°˜ ìŠ¤íŒ¸ í™•ë¥  ë° ì¤‘ìš” ë‹¨ì–´ ì¶”ì¶œ.

    Parameters:
        processed_message (str): ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
        vectorizer: ì‚¬ì „ í•™ìŠµëœ CountVectorizer
        model: í•™ìŠµëœ Naive Bayes ëª¨ë¸
        top_n (int): ì¤‘ìš” ë‹¨ì–´ ì¶”ì¶œ ê°œìˆ˜

    Returns:
        spam_prob (float): ìŠ¤íŒ¸ì¼ í™•ë¥ 
        important_words (list): ì¤‘ìš” ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
        message_vec: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ì˜ ë²¡í„° 
    """

    message_vec = vectorizer.transform([processed_message])
    log_probs = model.feature_log_prob_
    indices = message_vec.indices
    counts = message_vec.data

    # í´ë˜ìŠ¤ë³„ ë¡œê·¸ìš°ë„ê¸°ë°˜ í™•ë¥  ê³„ì‚°
    class_log_likelihoods = []
    for class_idx in range(len(model.classes_)):
        log_likelihood = 0
        for i, idx in enumerate(indices):
            log_likelihood += counts[i] * log_probs[class_idx, idx]
        class_log_likelihoods.append(log_likelihood)

    length = np.sum(counts)
    if length == 0:
        return None, None  # ì…ë ¥ ì˜¤ë¥˜ ì²˜ë¦¬ìš©

    # í‰ê·  ë¡œê·¸ìš°ë„ + í´ë˜ìŠ¤ ì‚¬ì „í™•ë¥ 
    avg_log_likelihoods = np.array(class_log_likelihoods) / length
    class_log_prior = np.log(model.class_count_ / model.class_count_.sum())
    scores = class_log_prior + avg_log_likelihoods

    # softmax ë³€í™˜
    exp_scores = np.exp(scores - np.max(scores))
    probs = exp_scores / exp_scores.sum()

    spam_prob = probs[model.classes_.tolist().index(1)]

    # ì¤‘ìš” ë‹¨ì–´ ì¶”ì¶œ
    top_indices = indices[np.argsort(-counts)[:top_n]]
    important_words = [vectorizer.get_feature_names_out()[i] for i in top_indices]

    return spam_prob, important_words

def find_optimal_k(X, max_k=12):
    """
    kmeans ì‚¬ìš©ì‹œ ìµœì ì˜ k ê°¯ìˆ˜ë¥¼ ì°¾ìŒ.
    X -> ë²¡í„°í™” ë°ì´í„°
    max_k -> ìµœëŒ€ Kê°œìˆ˜ ì„¤ì •
    """
    inertia = []
    silhouette = []
    K = range(2, max_k+1)
    for k in K:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(X)
        inertia.append(kmeans.inertia_)
        silhouette.append(silhouette_score(X, kmeans.labels_))
    
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(K, inertia, 'o-')
    plt.xlabel('Number of clusters K')
    plt.ylabel('Inertia (WCSS)')
    plt.title('Elbow Method')

    plt.subplot(1, 2, 2)
    plt.plot(K, silhouette, 'o-')
    plt.xlabel('Number of clusters K')
    plt.ylabel('Silhouette Score')
    plt.title('Silhouette Score')


    plt.show()

def get_final_spam_message(nb_prob, rf_prob, if_prob, low=0.4, high=0.5):
    def classify_status(prob, low, high):
        if prob < low:
            return "normal"
        elif prob < high:
            return "suspicious"
        else:
            return "danger"

    # ìƒíƒœ ë¶„ë¥˜
    nb_status = classify_status(nb_prob, low, high)
    rf_status = classify_status(rf_prob, low, high)
    if_status = "spam" if if_prob > 0.5 else "outlier"

    # NB ì„¤ëª…
    nb_desc = {
        "normal": "ğŸ“ 1. ë‹¨ì–´ êµ¬ì„± ê²€í† : ë‹¨ì–´ êµ¬ì„±ì€ ì•ˆì „í•´ ë³´ì…ë‹ˆë‹¤.",
        "suspicious": "ğŸ“ 1. ë‹¨ì–´ êµ¬ì„± ê²€í† : ì¼ë¶€ ë‹¨ì–´ë“¤ ì¤‘ ìŠ¤íŒ¸ ë©”ì‹œì§€ì—ì„œ ìì£¼ ì“°ì´ëŠ” í‘œí˜„ë“¤ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "danger": "ğŸ“ 1. ë‹¨ì–´ êµ¬ì„± ê²€í† : ë‹¨ì–´ë“¤ì´ ìŠ¤íŒ¸ì„± í‘œí˜„ìœ¼ë¡œ ê°•í•˜ê²Œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
    }[nb_status]

    # RF ì„¤ëª…
    rf_desc = {
        "normal": "ğŸ” 2. íŒ¨í„´ ê²€í† : í•´ë‹¹ ë©”ì‹œì§€ì˜ íŒ¨í„´ì€ ì¼ë°˜ì ì¸ ì •ìƒ ë©”ì‹œì§€ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.",
        "suspicious": "ğŸ” 2. íŒ¨í„´ ê²€í† : í•´ë‹¹ ë©”ì‹œì§€ íŒ¨í„´ì— ìŠ¤íŒ¸ì„± íŒ¨í„´ì´ ì¼ë¶€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
        "danger": "ğŸ” 2. íŒ¨í„´ ê²€í† : í•´ë‹¹ ë©”ì‹œì§€ íŒ¨í„´ì€ ì „í˜•ì ì¸ ìŠ¤íŒ¸ íŒ¨í„´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤."
    }[rf_status]

    # IF ì„¤ëª…
    if_desc = {
        "spam": "ğŸ§© 3. ê¸°ì¡´íŒ¨í„´ ì¼ì¹˜ë„: ì´ ë©”ì‹œì§€ëŠ” ê¸°ì¡´ì— í•™ìŠµëœ ë¬¸ì¥ íŒ¨í„´ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.",
        "outlier": "ğŸ§© 3. ê¸°ì¡´íŒ¨í„´ ì¼ì¹˜ë„: ê¸°ì¡´ ë¬¸ì¥ íŒ¨í„´ê³¼ëŠ” ë‹¤ì†Œ ë‹¤ë¥¸ ìƒˆë¡œìš´ í˜•íƒœë¡œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. \n ğŸ¤· ëŒ€ë¶€ë¶„ ì •ìƒì´ê² ë‹¤ë§Œ, ì‹ ì¢… ìŠ¤íŒ¸ì¼ìˆ˜ë„?"
    }[if_status]

    # ì¢…í•© ê²°ë¡ 
    if nb_status == "normal" and rf_status == "normal":
        conclusion = "âœ… í˜„ì¬ë¡œì„œëŠ” ì•ˆì „í•œ ë©”ì‹œì§€ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
    elif (nb_status == "danger" or nb_status == "suspicious") and (rf_status == "danger" or rf_status == "suspicious") and if_status == "spam":
        conclusion = "ğŸš¨ ìŠ¤íŒ¸ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë‹ˆ ë§¤ìš° ì¡°ì‹¬ ìš”ë§í•©ë‹ˆë‹¤!"
    else:
        conclusion = "âš ï¸ ìŠ¤íŒ¸ ê°€ëŠ¥ì„±ì´ ì˜ì‹¬ë˜ë¯€ë¡œ, ì£¼ì˜í•˜ëŠ” ê²ƒë„ ë‚˜ì˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    # ìµœì¢… ë©”ì‹œì§€
    final_message = f"ğŸ“Œ ì¢…í•© íŒë‹¨ ì„¤ëª…\n{nb_desc}\n{rf_desc}\n{if_desc}\n\n{conclusion}"

    return final_message

