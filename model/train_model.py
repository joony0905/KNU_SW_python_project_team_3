import sys 
import os

if __name__ == '__main__':
    ROOT_DIR = os.getcwd()  #ìƒìœ„ í´ë”ë„ ì¸ì‹í•˜ê¸° ìœ„í•¨ 
    if ROOT_DIR not in sys.path:
        sys.path.insert(0, ROOT_DIR)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.cluster import KMeans
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import swifter
import joblib
from utils.model_utils import *
from data_loader import *
from utils.file_io import *
from utils.preprocessing import clean_text, tokenize_and_filter
from scipy.sparse import hstack, csr_matrix 
from sklearn.calibration import CalibratedClassifierCV
import numpy as np

swifter.set_defaults(display_progress=True)
swifter.set_defaults(allow_dask_on_strings=False)

def naive_train_and_evaluate_model(
    combined_df_path='data/processed/cleaned_data.csv',
    vectorizer_path='model/nv_tf_idf_vectorizer.pkl',
    model_path='model/nv_spam_classifier.pkl',
    iso_model_path='model/isotonic_nv_spam_classifier.pkl',
    raw_phishing_path='data/raw/init_phishing.csv',
    raw_normal_path='data/raw/generated_30k_ad_messages.csv',
    raw_chat_path='data/raw/comments_1.csv',
    test_size=0.2,
    random_state=42,
    max_features=15000
):
    try:
        if os.path.exists(combined_df_path):
            print(f"{combined_df_path} íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")
            combined_df = naive_load_csv(combined_df_path, encoding = 'utf-8-sig')
        else:
            print(f"{combined_df_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            combined_df = naive_load_and_prepare_data(
                phishing_path=raw_phishing_path,
                normal_path=raw_normal_path,
                chat_path=raw_chat_path
            )

            combined_df['message'] = (
                combined_df['message']
                .astype(str)
                .swifter.apply(lambda x: tokenize_and_filter(clean_text(x)))
            )
            naive_save_dataframe_to_csv(combined_df, combined_df_path)
            print("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError as e:
        print(f"ì˜¤ë¥˜: {e}")
        return  

    X = combined_df['message']
    y = combined_df['label']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y)

    if os.path.exists(vectorizer_path):
        while True:
            try:
                flag = int(input("ë²¡í„°ë¼ì´ì €ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•˜ì‹œë ¤ë©´ 0 / ê¸°ì¡´ íŒŒì¼ì„ Loadí•˜ë ¤ë©´ 1ì„ ì…ë ¥í•˜ì„¸ìš”. "))
                if(flag == 1):           
                    vectorizer = joblib.load(vectorizer_path)
                    print(f"ë²¡í„°ë¼ì´ì € '{vectorizer_path}'ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    break
                elif(flag == 0):
                    vectorizer = TfidfVectorizer(max_features=max_features)
                    print("ë²¡í„°ë¼ì´ì €ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    break
                else:
                    print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except:
                print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        vectorizer = TfidfVectorizer(max_features=max_features)
        print(f"ë²¡í„°ë¼ì´ì € '{vectorizer_path}'ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)

    if os.path.exists(model_path):
        while True:
            try:
                flag = int(input("ê¸°ì¡´ í•™ìŠµ ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•˜ì‹œë ¤ë©´ 0 / ê¸°ì¡´ íŒŒì¼ì„ Loadí•˜ë ¤ë©´ 1ì„ ì…ë ¥í•˜ì„¸ìš”. "))
                if(flag == 1):           
                    model = joblib.load(model_path)
                    print(f"ê¸°ì¡´ í•™ìŠµ ëª¨ë¸ '{model_path}'ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    break
                elif(flag == 0):
                    print("ëª¨ë¸ì„ ìƒˆë¡œ ìƒì„±í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.")
                    model = MultinomialNB()
                    model.fit(X_train_vec, y_train)
                    break
                else:
                    print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except:
                print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        model = MultinomialNB()
        model.fit(X_train_vec, y_train)
        print(f"ëª¨ë¸ '{model_path}'ê°€ ì—†ì–´ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")

    y_pred = model.predict(X_test_vec)

    print(confusion_matrix(y_test, y_pred))
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)

    disp.plot(cmap='Blues')
    plt.title('Confusion Matrix')
    plt.show()

    #sigmo_model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=3)
    #sigmo_model.fit(X_train_vec, y_train)

    #iso_model = CalibratedClassifierCV(estimator=model, method='isotonic', cv=5)
    #iso_model.fit(X_train_vec, y_train)

    plot_calibration_curve(model, X_test_vec, y_test, model_name="Naive_Bayes", n_bins=20)
    #plot_calibration_curve(sigmo_model, X_test_vec, y_test, model_name="sigmo_Naive_Bayes", n_bins=20)
    #plot_calibration_curve(iso_model, X_test_vec, y_test, model_name="iso_Naive_Bayes", n_bins=20)

    flag = int(input("í˜„ì¬ ë²¡í„°ë¼ì´ì €ì™€ í•™ìŠµ ëª¨ë¸ì„ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1: ì˜ˆ / 0: ì•„ë‹ˆì˜¤ " ))
    while True:
        try:
            if(flag == 1):
                joblib.dump(model, model_path) 
                #joblib.dump(iso_model, iso_model_path)
                joblib.dump(vectorizer, vectorizer_path)
                print("ë²¡í„°ë¼ì´ì €ì™€ ëª¨ë¸ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                break
            elif(flag == 0):
                return
            else:
                print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except:
            print("ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def rf_train_and_evaluate_model(
    combined_df_path='data/processed/rf_cleaned_data.csv',
    vectorizer_path='model/rf_count_vectorizer.pkl',
    model_path='model/rf_spam_classifier.pkl',
    iso_model_path='model/rf_isotonic_spam_classifier.pkl',
    category_columns_path='model/rf_category_columns.pkl',
    test_size=0.2,
    random_state=42,
    max_features=10000):
    try:
        if os.path.exists(combined_df_path):
            print(f"{combined_df_path} íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            combined_df = pd.read_csv(combined_df_path, encoding='utf-8-sig')
        else:
            print(f"{combined_df_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
            combined_df = rf_load_and_prepare_data()

            # 1. ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë”°ë¡œ ì €ì¥
            combined_df['processed'] = (
                combined_df['message']
                .astype(str).swifter.apply(lambda x: tokenize_and_filter(clean_text(x))))

            # 2. ì „ì²˜ë¦¬ëœ ê°’ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
            combined_df = combined_df.drop_duplicates(subset='processed').reset_index(drop=True)

            combined_df['label'] = combined_df['label'].map({'ham': 0, 'spam': 1})
            rf_save_dataframe_to_csv(combined_df, combined_df_path, index=False, encoding='utf-8-sig')
            print("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except FileNotFoundError as e:
        print(f"ì˜¤ë¥˜: {e}")
        return

    if os.path.exists(vectorizer_path):
        while True:
            try:
                flag = int(input("Count ë²¡í„°ë¼ì´ì €ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ ìƒì„± 0 / ë¶ˆëŸ¬ì˜¤ê¸° 1: "))
                if flag == 1:
                    vectorizer = joblib.load(vectorizer_path)
                    print("ë²¡í„°ë¼ì´ì €ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    #print(type(vectorizer))
                    break
                elif flag == 0:
                    vectorizer = CountVectorizer(
                    max_features=20000,
                    ngram_range=(1, 1), 
                    min_df=3,           
                    max_df=0.95           
                    )
                    print("ìƒˆ ë²¡í„°ë¼ì´ì €ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    break
                else:
                    print("0 ë˜ëŠ” 1ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except:
                print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
    else:
        vectorizer = CountVectorizer(
                    max_features=20000,
                    ngram_range=(1,1), 
                    min_df=3,            
                    max_df=0.95           
                    )
        print("ë²¡í„°ë¼ì´ì €ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    # ì¹´í…Œê³ ë¦¬ ì›í•« ì „ì²´ ì—´ í™•ë³´ (ì „ì²´ ì»¬ëŸ¼ ìœ ì§€ìš©)
    category_onehot = pd.get_dummies(combined_df['category'])
    
    #adëŠ” ê´‘ê³ ë¬¸ì ì´ë§ë¼. ì¹´í…Œê³ ë¦¬ ì œì™¸
    category_onehot = category_onehot.drop(columns=['ad'], errors='ignore')
    
    # 3. í•™ìŠµ ì‹œì—ë„ 'processed' ì‚¬ìš©
    train_df, test_df = train_test_split(combined_df, test_size=0.2, stratify=combined_df['label'], random_state=42)
    X_train = vectorizer.fit_transform(train_df['processed'])
    X_test = vectorizer.transform(test_df['processed']) 

    #ë¬¸ì¥ ê¸¸ì´ feature ì¶”ê°€
    len_train = csr_matrix([[len(msg.split())] for msg in train_df['processed']])
    len_test = csr_matrix([[len(msg.split())] for msg in test_df['processed']])

    #one hot ì—†ì´ í–ˆì„ë•Œë‘ ë¹„êµ
    #X_train = vectorizer.fit_transform(train_df['processed'])  
    #X_test = vectorizer.transform(test_df['processed']) 

    # ì¹´í…Œê³ ë¦¬ ì›í•« ì¸ì½”ë”©: ì»¬ëŸ¼ ì¼ì¹˜ ë³´ì¥
    cat_train = pd.get_dummies(train_df['category']).reindex(columns=category_onehot.columns, fill_value=0)
    cat_test = pd.get_dummies(test_df['category']).reindex(columns=category_onehot.columns, fill_value=0)



    cat_train_sparse = csr_matrix(cat_train.values)
    cat_test_sparse = csr_matrix(cat_test.values)
    
    # ìµœì¢… ê²°í•©
    X_train = hstack([X_train, len_train, cat_train_sparse])
    X_test = hstack([X_test, len_test, cat_test_sparse])
    y_train = train_df['label']
    y_test = test_df['label']

    if os.path.exists(model_path):
        while True:
            try:
                flag = int(input("ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œ í•™ìŠµ 0 / ë¶ˆëŸ¬ì˜¤ê¸° 1: "))
                if flag == 1:
                    model = joblib.load(model_path)
                    print("ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    break
                elif flag == 0:
                    model = RandomForestClassifier(
                        n_estimators=300,
                        max_depth=15,
                        min_samples_leaf=30,
                        min_samples_split=30,
                        max_features='sqrt',
                        class_weight=None,
                        random_state=42,
                        n_jobs=-1)
                    model.fit(X_train, y_train)
                    print("ëª¨ë¸ì„ ìƒˆë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.")
                    break
                else:
                    print("0 ë˜ëŠ” 1ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except:
                print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
    else:
        model = RandomForestClassifier(
                    n_estimators=300,
                    max_depth=15,
                    min_samples_leaf=30,
                    min_samples_split=30,
                    max_features='sqrt',
                    class_weight=None,
                    random_state=42,
                    n_jobs=-1)
        model.fit(X_train, y_train)
        print("ëª¨ë¸ì´ ì—†ì–´ ìƒˆë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.")

    y_pred = model.predict(X_test)
    print("ì •í™•ë„:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    #disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred))
    #disp.plot(cmap='Blues')
    #plt.title('Random Forest Confusion Matrix')
    #plt.show()

    # ê¸°ì¡´ ëª¨ë¸ì„ ê°ì‹¸ì„œ ë³´ì •
    # iso_model = CalibratedClassifierCV(estimator=model, method='isotonic', cv=5)
    # #sigmo_model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)

    # iso_model.fit(X_train, y_train)
    # #sigmo_model.fit(X_train, y_train)
    # iso_y_pred = iso_model.predict(X_test)
    # print("Calibrated isotonic ë³´ì • ëª¨ë¸ \nì •í™•ë„:", accuracy_score(y_test, iso_y_pred))
    # print(classification_report(y_test, iso_y_pred))

    #sigmo_model = CalibratedClassifierCV(estimator=model, method='sigmoid', cv=5)
    #sigmo_model.fit(X_train, y_train)
    #plot_calibration_curve(model, X_test, y_test, model_name="general_RF_Model") #calibê³¡ì„  ì‹œê°í™”
    #plot_calibration_curve(iso_model, X_test, y_test, model_name="iso_RF_Model")
    #plot_calibration_curve(sigmo_model, X_test, y_test, model_name="sigmo_RF_Model")

    while True:
        try:
            flag = int(input("í•™ìŠµ ëª¨ë¸ íŒŒì¼ë“¤ì„ ì €ì¥í• ê¹Œìš”? 1: ì˜ˆ / 0: ì•„ë‹ˆì˜¤ "))
            if flag == 1:
                joblib.dump(model, model_path)
                joblib.dump(vectorizer, vectorizer_path)
                joblib.dump(category_onehot.columns.tolist(), category_columns_path)
                print("í•™ìŠµ ëª¨ë¸ íŒŒì¼ë“¤ë“¤ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                break
            elif flag == 0:
                break
            else:
                print("0 ë˜ëŠ” 1ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")


def k_means_clustering(
    if_phishing_path='data/processed/if_cleand_data.csv',
    init_phishing_path = 'data/raw/init_phishing.csv',
    vectorizer_path='model/if_count_vectorizer.pkl',
    kmeans_model_path='model/kmeans_spam.pkl',
    num_clusters=2
):

    # ìŠ¤íŒ¸ ì›ë³¸ ë°ì´í„° ë¡œë“œ
    if os.path.exists(if_phishing_path):
        spam_df = pd.read_csv(if_phishing_path, encoding='utf-8-sig')
        print(f"ìŠ¤íŒ¸ ì „ì²˜ë¦¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(spam_df)} rows")
    else:
        print(f"{if_phishing_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
        spam_df = pd.read_csv(init_phishing_path, encoding='cp949')
        spam_df['message'] = (
                spam_df['Spam message']
                .astype(str)
                .swifter.apply(lambda x: tokenize_and_filter(clean_text(x)))
            )
        spam_df.to_csv(if_phishing_path, index=False, columns=['message'], encoding='utf-8-sig')
        print("ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ì™„ë£Œ")

    # ë²¡í„°ë¼ì´ì € ë¡œë“œ
    if os.path.exists(vectorizer_path):
        vectorizer = joblib.load(vectorizer_path)
        print("CountVectorizer ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"{vectorizer_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. if_count ë²¡í„°ë¼ì´ì €ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..")
        vectorizer = CountVectorizer(
                    max_features=20000,
                    ngram_range=(1,1), 
                    min_df=3,            
                    max_df=0.95           
                    )
        vectorizer.fit(spam_df['message'])
        joblib.dump(vectorizer, vectorizer_path)
        print("vectorizer ìƒì„± ë° ì €ì¥")
        
    
    
    # ë²¡í„°í™”
    X_spam = vectorizer.transform(spam_df['message'])

    #find_optimal_k(X_spam[:10000], max_k=8)
    #k=2ê°€ ì œì¼ ì¢‹ì€ ì„±ëŠ¥ ë³´ì˜€ìŒ..
    #return


    # KMeans í•™ìŠµ
    sample_size = min(50_000, X_spam.shape[0])
    print(f"ğŸ“Œ KMeans í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘: {num_clusters}ê°œ í´ëŸ¬ìŠ¤í„° (ìƒ˜í”Œ {sample_size}ê°œ)")
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(X_spam[:sample_size])

    # ì „ì²´ ìŠ¤íŒ¸ ë°ì´í„°ì— í´ëŸ¬ìŠ¤í„° ID ë¶€ì—¬
    spam_clusters = kmeans.predict(X_spam)
    spam_df['category'] = spam_clusters

    # ì €ì¥ ì—¬ë¶€ ì„ íƒ
    while True:
        try:
            flag = int(input("KMeans ëª¨ë¸ê³¼ ì¹´í…Œê³ ë¦¬ ê²°ê³¼ë¥¼ ì €ì¥í• ê¹Œìš”? 1: ì˜ˆ / 0: ì•„ë‹ˆì˜¤ "))
            if flag == 1:
                # ì¹´í…Œê³ ë¦¬ ë¶™ì€ CSV (ì„ íƒ) ì €ì¥
                new_csv_path = if_phishing_path.replace('.csv', '_with_category.csv')
                spam_df.to_csv(new_csv_path, index=False, columns=['message', 'category'], encoding='utf-8-sig')
                # KMeans ëª¨ë¸ ì €ì¥
                joblib.dump(kmeans, kmeans_model_path)
                print(f"ì €ì¥ ì™„ë£Œ: {new_csv_path}, {kmeans_model_path}")
                break
            elif flag == 0:
                print("ì €ì¥í•˜ì§€ ì•Šê³  ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            else:
                print("0 ë˜ëŠ” 1ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")



def if_train_and_evaluate_model(
    category_phishing_path='data/processed/if_cleand_data_with_category.csv',
    vectorizer_path='model/if_count_vectorizer.pkl',
    kmeans_model_path='model/kmeans_spam.pkl',
    if_model_dir='model/category_if_models/',
    contamination=0.01,
    min_samples_per_category=500,  # âœ… ì†Œí˜• ê¸°ì¤€
    merged_category_id=999         # âœ… ê¸°íƒ€ë¡œ ë³‘í•©í•  ID
):

    os.makedirs(if_model_dir, exist_ok=True)

    # 1) ì¹´í…Œê³ ë¦¬ í¬í•¨ ìŠ¤íŒ¸ ë°ì´í„° ë¡œë“œ
    if os.path.exists(category_phishing_path):
        spam_df = pd.read_csv(category_phishing_path, encoding='utf-8-sig')
        print(f"ğŸ“Œ ì¹´í…Œê³ ë¦¬ í¬í•¨ ìŠ¤íŒ¸ ë¡œë“œ ì™„ë£Œ: {len(spam_df)} rows")
    else:
        print(f"{category_phishing_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # 2) Vectorizer ë¡œë“œ
    if os.path.exists(vectorizer_path):
        vectorizer = joblib.load(vectorizer_path)
    else:
        print(f"{vectorizer_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # 3) KMeans ë¡œë“œ
    if os.path.exists(kmeans_model_path):
        kmeans = joblib.load(kmeans_model_path)
    else:
        print(f"{kmeans_model_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # 4) ë²¡í„°í™”
    X_spam = vectorizer.transform(spam_df['message'])

    # 5) category ì—†ìœ¼ë©´ KMeansë¡œ ì˜ˆì¸¡
    if 'category' not in spam_df.columns:
        spam_df['category'] = kmeans.predict(X_spam)
        print(f"ğŸ“Œ KMeansë¡œ category ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

    # 6) ì†Œí˜• í´ëŸ¬ìŠ¤í„° ì‹ë³„ & ë³‘í•©
    small_clusters = []
    merged_indices = []

    for category_id in spam_df['category'].unique():
        n_samples = (spam_df['category'] == category_id).sum()
        if n_samples < min_samples_per_category:
            small_clusters.append(category_id)
            merged_indices.extend(spam_df[spam_df['category'] == category_id].index.tolist())

    if merged_indices:
        spam_df.loc[merged_indices, 'category'] = merged_category_id
        print(f"âš™ï¸ ì†Œí˜• í´ëŸ¬ìŠ¤í„° {small_clusters} ë³‘í•© â†’ 'ê¸°íƒ€' Category {merged_category_id} (ì´ {len(merged_indices)} samples)")
    else:
        print("âœ… ì†Œí˜• í´ëŸ¬ìŠ¤í„° ì—†ìŒ â†’ ë³‘í•© ìƒëµ")

    # 7) ì¹´í…Œê³ ë¦¬ë³„ IF í•™ìŠµ
    if_models = {}
    score_ranges = {}  # ì¹´í…Œê³ ë¦¬ë³„ score ë²”ìœ„ ê¸°ë¡
    for category_id in spam_df['category'].unique():
        X_cat = X_spam[spam_df['category'] == category_id]
        n_samples = X_cat.shape[0]

        if n_samples < min_samples_per_category:
            print(f"âš ï¸ Category {category_id} : {n_samples}ê°œ â†’ ë„ˆë¬´ ì ì–´ IF ìŠ¤í‚µ")
            continue

        print(f"ğŸ“Œ Category {category_id} : {n_samples}ê°œ â†’ IF í•™ìŠµ")
        if_model = IsolationForest(contamination=contamination, random_state=42)
        if_model.fit(X_cat)
        if_models[category_id] = if_model

        # í•™ìŠµ ë°ì´í„°ì—ì„œ decision_function ì ìˆ˜ ë²”ìœ„ í™•ì¸
        try:
            scores = if_model.decision_function(X_cat)
            score_min, score_max = scores.min(), scores.max()
            print(f"   â”— decision_function score: min={score_min:.4f}, max={score_max:.4f}")
            score_ranges[category_id] = {
            "min": score_min,
            "max": score_max
            }
        except Exception as e:
            print(f"   âš ï¸ ìŠ¤ì½”ì–´ ê³„ì‚° ì˜¤ë¥˜: {e}")

    # âœ… 8) ì €ì¥ ì—¬ë¶€
    while True:
        try:
            flag = int(input("score_range ë° ì¹´í…Œê³ ë¦¬ë³„ IF ëª¨ë¸ ì €ì¥í• ê¹Œìš”? 1: ì˜ˆ / 0: ì•„ë‹ˆì˜¤ ").strip())
            if flag == 1:
                for cid, if_model in if_models.items():
                    path = os.path.join(if_model_dir, f"if_category_{cid}.pkl")
                    joblib.dump(if_model, path)
                    print(f"âœ… ì €ì¥ ì™„ë£Œ: {path}")
                ranges_path = os.path.join(if_model_dir, "if_score_ranges.pkl")
                joblib.dump(score_ranges, ranges_path)
                print(f"âœ… score_ranges ì €ì¥ ì™„ë£Œ: {ranges_path}")
                break
            elif flag == 0:
                print("ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                break
            else:
                print("0 ë˜ëŠ” 1ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")






if __name__ == '__main__':
    #naive_train_and_evaluate_model()
    #rf_train_and_evaluate_model() 
    #k_means_clustering()
    if_train_and_evaluate_model()
